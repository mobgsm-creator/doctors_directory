import pandas as pd
import numpy as np
import os
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from fuzzywuzzy import fuzz

dir = r"C:\Users\agney\Desktop\Aesthetic Products\Raw"

def read_all_csv_and_xlsx_files(dir):
    files = os.listdir(dir)
    dfs = []
    total_length=0

    for index, file in enumerate(files):
        try:
            if file.endswith(".csv"):
                print("csv file at index", index)
                df = pd.read_csv(os.path.join(dir, file), encoding='latin-1')
                result =consolidate_file(df)
                dfs.append(result)
                total_length+=len(df)
            elif file.endswith(".xlsx"):
                print("xlsx file at index", index)
                sheet_names = pd.ExcelFile(os.path.join(dir, file)).sheet_names
                for name in sheet_names:
                    df = pd.read_excel(os.path.join(dir, file), sheet_name=name)
                    result =consolidate_file(df)
                    dfs.append(result)
                    total_length+=len(df)
            print("✅ File processed. Total length of dataframes is", total_length)
        except Exception as e:
            print(e)  
    master_df = pd.concat(dfs, ignore_index=True)
    master_df.to_excel(r"C:\Users\agney\Desktop\Aesthetic Products\consolidated_output.xlsx", index=False)
    print("✅ Consolidation complete. Saved to consolidated_output.csv")
# Your final standardized headers
FINAL_NAME = "Product Name"
FINAL_PRICE = "Product Price"
FINAL_URL = "Product URL"
FINAL_TEXT = "full_text"

# Possible column variations that might map to each final header
NAME_MAP = [
    "Name", "Product Name", "Product_name", "product_name", "Product_Name",
    "Product Name", "Product_title", "Product Title", "product_title", "Product_name"
]

PRICE_MAP = [
    "Price", "Product Price", "Product_price", "Product_price", "product_price",
    "product price", "Product_Price", "Retail_price", "Product_price_display",
    "detailed_price", "price_display", "Product_price_display", "Product_price"
]

URL_MAP = [
    "URL", "Link", "Product URL", "Product_url", "product_url", "Product_URL",
    "Product Link", "Product link", "Link", "Product URL"
]

def pick_column(df, candidates):
    """Return the first matching column from candidate list that exists in df"""
    for col in candidates:
        for existing in df.columns:
            if existing.lower() == col.lower():
                return existing
    return None     

def consolidate_file(df):

    # Identify best matching columns
    name_col = pick_column(df, NAME_MAP)
    price_col = pick_column(df, PRICE_MAP)
    url_col = pick_column(df, URL_MAP)

    # Create standardized dataframe
    new_df = pd.DataFrame()
    new_df[FINAL_NAME] = df[name_col] if name_col else ""
    new_df[FINAL_PRICE] = df[price_col] if price_col else ""
    new_df[FINAL_URL] = df[url_col] if url_col else ""

    # Concatenate all remaining columns into full_text
    remaining_cols = [c for c in df.columns if c not in [name_col, price_col, url_col]]
    new_df[FINAL_TEXT] = df[remaining_cols].fillna("").astype(str).agg(" ".join, axis=1) if remaining_cols else ""

    return new_df     
#read_all_csv_and_xlsx_files(dir)
# df = pd.read_excel(r"C:\Users\agney\Desktop\Aesthetic Products\consolidated_output.xlsx", sheet_name='Sheet2')

# blacklist = ['ml','g','mm','v','in','litre','kg','mgml','xmg','mg','sachets','capsules','sugarfree','batch', 'of','fat','mlx','single','vial','solution','dispersible','tablets','botulinum','vials','xu','xiu','pdr','sol','neurotoxin',   'type','twin','pack''for','xml','dual','single','iu','buy','rich','night','daily','moisturizing','gentle','hydrating','sugar','free','suspension','and','renewing','mcg','foam','foaming','inj','injection','pwd','units','capsule','ampoule','ampoules']
# def clean_tokens(s: str):
#     s = s.lower().strip()
#     raw = s.split()

#     tokens = []
#     for token in raw:
#         letters = "".join([ch for ch in token if ch.isalpha()])
#         if letters:
#             if letters not in blacklist:
#                 if len(letters) > 1:
#                     tokens.append(letters)

#     return tokens


# # Step 1: build token lists for all rows
# df["tokens"] = df["Product Name"].apply(clean_tokens)

# # Step 2: extract first-token brands
# df["brand"] = df["tokens"].apply(lambda t: t[0] if t else None)

# # Step 3: find brands that have multiple second tokens
# from collections import defaultdict
# families = defaultdict(set)

# for t in df["tokens"]:
#     if len(t) > 1:
#         families[t[0]].add(t[1])

# # Step 4: build final keys
# def final_key(tokens):
#     if not tokens:
#         return None

#     brand = tokens[0]

#     # If brand has more than one family, keep two tokens
#     if len(families[brand]) > 1 and len(tokens) > 1:
#         return brand + " " + tokens[1]

#     # Else only brand
#     return brand

# df["key"] = df["tokens"].apply(final_key)


# df.to_excel(r"C:\Users\agney\Desktop\Aesthetic Products\similarity_scores.xlsx", index=False)


#read consolidated_output.csv
#What we can do: 1. Split string and check keyword match 2. fuzzywuzzy 3. contextual embeddings
df = pd.read_excel(r"C:\Users\agney\Desktop\Aesthetic Products\similarity_scores.xlsx", sheet_name='onlyPrice')
df["price_dict"] = df.apply(
    lambda r: {"price": r["Product Price"], "url": r["Product URL"]},
    axis=1
)
grouped = df.groupby("key")["price_dict"].apply(list).reset_index()
grouped.columns = ["key", "all_prices"]
df = df.merge(grouped, on="key", how="left")
df.to_excel(r"C:\Users\agney\Desktop\Aesthetic Products\Grouped_Data.xlsx", index=False)